{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4b7d3acc","cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\n\nfrom PIL import Image\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import Adam, AdamW, SGD","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"daa5cf52","cell_type":"code","source":"!git clone https://github.com/VikramShenoy97/Human-Segmentation-Dataset.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"570da81a","cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, image_dir, mask_dir):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.transform = transforms.Compose([\n            transforms.Resize((512,512)),\n            transforms.ToTensor()\n        ])\n\n        valid_extension = {\".jpg\",\".jpeg\",\".png\"}\n        self.images = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in valid_extension]\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem(self, idx):\n        image_path= os.path.join(self.image_dir, self.images[idx])\n        name, ext = os.path.splitext(self.images[idx])\n        mask_path= os.path.join(self.mask_dir, f\"{name}.png\")\n\n        image = Image.open(image_path).convert(\"RGB\")\n        mask = Image.open(mask_path).convert(\"L\")\n\n        mask = (mask >0.5).float()\n\n        return image, mask\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fee9f3b7","cell_type":"code","source":"## Data loader \n\ndef get_dataloader(image_dir, maks_dir, batch_size =2, shuffle =True):\n    dataset = SegmentationDataset(image_dir, maks_dir)\n    return DataLoader(dataset, batch_size = batch_size, shuffle =shuffle)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"11cccdb3","cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv_op = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1),\n            nn.ReLU(inplace =True),\n            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1),\n            nn.ReLU(inplace =True)\n        )\n    def forward(self, x):\n        return self.conv_op(x)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c340b793","cell_type":"code","source":"## this downsample need to take care of as two conv and one max pooling\n\nclass DownSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = DoubleConv(in_channels, out_channels)\n        self.pool =nn.MaxPool2d(kernel_size =2, stride =2)\n    def forward(self, x):\n        down = self.conv(x) ## convolve, this need be saved for upsampling\n        p = self.pool(down) ## the pooling stuff\n        return down, p","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c21bd7d8-6bb3-43c8-af52-6898547f72b8","cell_type":"code","source":"class UpSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size =2, stride =2)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        x = torch.cat([x1,x2],1)\n        return self.conv(x)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c59ce611","cell_type":"code","source":"### Unet\n\nclass Unet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.down_conv1= DownSample(in_channels, 64) ## output is 64\n        self.down_conv2= DownSample(64, 128)\n        self.down_conv3= DownSample(128,256)\n        self.down_conv4= DownSample(256,512) \n\n        self.bottle_neck = DoubleConv(512, 1024)\n        \n        self.up_conv1= UpSample(1024, 512) ## output is 64\n        self.up_conv2= UpSample(512, 256)\n        self.up_conv3= UpSample(256,128)\n        self.up_conv4= UpSample(128,64)\n\n        self.out =nn.Conv2d(in_channels = 64, out_channels= num_classes, kernel_size =1)\n\n    def forward(self,x):\n        down_1, p1 = self.down_conv1(x)\n        down_2, p2 = self.down_conv2(p1)\n        down_3, p3 = self.down_conv3(p2)\n        down_4, p4 = self.down_conv4(p3)\n\n        b = self.bottle_neck(p4)\n\n        up1= self.up_conv1(b,down_4)\n        up2= self.up_conv2(up1,down_3)\n        up3= self.up_conv3(up2,down_2)\n        up4= self.up_conv4(up3,down_1)\n\n        out =self.out(up4)\n        return out\n        \n\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6a833220-5e40-458c-ab36-c3d0dc05006e","cell_type":"code","source":"## \n\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth = 1e-16):\n        super(DiceLoss, self).__init__()\n        self.smooth =smooth\n    def forward(self,inputs, targets):\n        inputs = inputs.view(-1)\n        targets =targets.view(-1)\n\n        intersection =(inputs * targets).sum()\n        dice_score = (2 * intersection + self.smooth)/(inputs.sum() + targets.sum() + self.smooth)\n\n        return 1 - dice_score\n\n\n\nclass BCEWithDiceLoss(nn.Module): \n    def __init__(self, smooth =1e-6):\n        super(BCEWithDiceLoss, self).__init__()\n        self.bce =nn.BCEWithDiceLoss()\n        self.dice = DiceLoss()\n\n    def forward(self, inputs, targets):\n        bce_loss = self.bce(inputs, targets)\n        dice_loss =self.dice(inputs, targets)\n        return 0.5 * bce_loss + dice_loss\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a4cc5d17-4bd8-4735-8438-dcb01ed37b1f","cell_type":"code","source":"## Training loop  Loss\n\ndef train(model, dataloader, epochs =2, lr =0.001, save_path  =\"unet_model\", load_path = None):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    if load_path and os.path.exists(load_path):\n        print(f\"Loading model weights  form{load_path}\")\n        model.load_state_dict(torch.load(load_path, map_location =device))\n    else : \n        print(f\"no checkpoint found, training from scratch..\")\n\n    print(device)\n    model.to(device)\n\n    criterion = BCEWithDiceLoss()\n\n    optimizer = SGD(model.parameters(), lr =lr)\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        \n        for images, masks, in dataloader:\n            images, masks = images.to(device), masks.to(device)\n            optimizer.zero_grad()\n\n            out = model(images)\n            \n            loss =criterion(output, masks)\n            loss.backward()\n            optimizer.steps()\n\n            epoch_loss +=loss.item()\n        \n        avg_loss =epoch_loss/ len(dataloader)\n\n        print(f\"epoch [{epoch+1}/{epochs}], Loss : {avg_loss: .4f}, LR: {lr}\")\n\n        if epoch %10==0 and epoch>0:\n            torch.save(model.state_dict(), f\"{save_path}.pth\")\n\n    torch.save(model.state_dict(), f\"{save_path}_final.pth\")\n    print(f\"Model_ saved to {save_path}\")\n\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"71b38b8c-dc9c-46ee-99e1-e3008403c097","cell_type":"code","source":"dataloader = get_dataloader(\"/kaggle/working/Human-Segmentation-Dataset/Training_Images\", \"/kaggle/working/Human-Segmentation-Dataset/Ground_Truth\", batch_size =8, shuffle=True)\n\nmodel = Unet(in_channels=3, num_classes=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"834cb76f","cell_type":"code","source":"train(model, dataloader, epochs =2, lr =0.001)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4b6e408e","cell_type":"markdown","source":"### Inference on trained model","metadata":{}},{"id":"2bf65557","cell_type":"code","source":"import numpy as np\n\n# Load model and predict with stats\ndef predict(model_path, input_image_path):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    # Load model\n    model = UNet(in_channels=3, num_classes=1)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    # Track start time\n    total_start_time = time.time()\n\n    # Image preprocessing\n    preprocess_start_time = time.time()\n    image = Image.open(input_image_path).convert(\"RGB\")\n    transform = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n    ])\n    image_tensor = transform(image).unsqueeze(0).to(device)\n    preprocess_end_time = time.time()\n\n    # Model inference\n    inference_start_time = time.time()\n    with torch.no_grad():\n        output = model(image_tensor)\n        output = torch.sigmoid(output)\n    inference_end_time = time.time()\n\n    # Postprocessing\n    postprocess_start_time = time.time()\n    mask = output.squeeze(0).squeeze(0).cpu().numpy()\n    mask = (mask > 0.4).astype(np.uint8) * 255\n    mask_image = Image.fromarray(mask)\n\n    combined = Image.new(\"RGB\", (512 * 2, 512))\n    combined.paste(image.resize((512, 512)), (0, 0))\n    combined.paste(mask_image.convert(\"RGB\"), (512, 0))\n    combined.save(\"output.jpg\")\n    postprocess_end_time = time.time()\n\n    # Calculate timing stats\n    total_end_time = time.time()\n\n    preprocess_time = preprocess_end_time - preprocess_start_time\n    inference_time = inference_end_time - inference_start_time\n    postprocess_time = postprocess_end_time - postprocess_start_time\n    total_time = total_end_time - total_start_time\n\n    # Print stats\n    print(\"\\nPrediction completed! Stats:\")\n    print(f\"  Image Preprocessing Time: {preprocess_time:.4f} seconds\")\n    print(f\"  Model Inference Time: {inference_time:.4f} seconds\")\n    print(f\"  Postprocessing Time: {postprocess_time:.4f} seconds\")\n    print(f\"  Total Prediction Time: {total_time:.4f} seconds\")\n    print(\"Prediction saved as output.jpg\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"afe10a45","cell_type":"code","source":"predict(model_path=\"/content/unet_model_80.pth\", input_image_path=\"/content/Human-Segmentation-Dataset/Training_Images/5.jpg\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"73fc774c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"213f6937","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}