{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4b7d3acc","cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\n\nfrom PIL import Image\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import Adam, AdamW, SGD","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:43:11.087171Z","iopub.execute_input":"2025-06-02T16:43:11.087539Z","iopub.status.idle":"2025-06-02T16:43:11.093966Z","shell.execute_reply.started":"2025-06-02T16:43:11.087516Z","shell.execute_reply":"2025-06-02T16:43:11.092817Z"}},"outputs":[],"execution_count":6},{"id":"daa5cf52","cell_type":"code","source":"!git clone https://github.com/VikramShenoy97/Human-Segmentation-Dataset.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T16:41:13.280971Z","iopub.execute_input":"2025-06-02T16:41:13.281327Z","iopub.status.idle":"2025-06-02T16:41:14.739264Z","shell.execute_reply.started":"2025-06-02T16:41:13.281306Z","shell.execute_reply":"2025-06-02T16:41:14.737890Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Human-Segmentation-Dataset'...\nremote: Enumerating objects: 596, done.\u001b[K\nremote: Total 596 (delta 0), reused 0 (delta 0), pack-reused 596 (from 1)\u001b[K\nReceiving objects: 100% (596/596), 13.60 MiB | 35.44 MiB/s, done.\nResolving deltas: 100% (7/7), done.\n","output_type":"stream"}],"execution_count":3},{"id":"570da81a","cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, image_dir, mask_dir):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.transform = transforms.Compose([\n            transforms.Resize((512,512)),\n            transforms.ToTesnsor()\n        ])\n\n        valid_extension = {\".jpg\",\".jpeg\",\".png\"}\n        self.images = [f for f in os.listdir(image_dir) if os.path.splittext(f)[1].lower() in valid_extension]\n\n    def __len(self):\n        return len(self.images)\n\n    def __getitem(self, idx):\n        image_path= os.path.join(self.image_dir, self.images[idx])\n        name, ext = os.path.splitext(self.images[idx])\n        image_path= os.path.join(self.mask_dir, f\"{name}.png\")\n\n        image = Image.open(image_path).convert(\"RGB\")\n        mask = Image.open(mask_path).convert(\"L\")\n\n        mask = (mask >0.5).float()\n\n        return image, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T17:55:07.825074Z","iopub.execute_input":"2025-06-02T17:55:07.825429Z","iopub.status.idle":"2025-06-02T17:55:07.833648Z","shell.execute_reply.started":"2025-06-02T17:55:07.825406Z","shell.execute_reply":"2025-06-02T17:55:07.832548Z"}},"outputs":[],"execution_count":13},{"id":"fee9f3b7","cell_type":"code","source":"## Data loader \n\ndef get_dataloader(image_dir, maks_dir, batch_size =2, shuffle =True):\n    dataset = SegmentationDataset(image_dir, maks_dir)\n    return DataLoader(dataset, batch_size = batch_size, shuffle =shuffle)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:07:08.563622Z","iopub.execute_input":"2025-06-02T18:07:08.564821Z","iopub.status.idle":"2025-06-02T18:07:08.570140Z","shell.execute_reply.started":"2025-06-02T18:07:08.564778Z","shell.execute_reply":"2025-06-02T18:07:08.568942Z"}},"outputs":[],"execution_count":14},{"id":"11cccdb3","cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv_op = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1),\n            nn.ReLU(inplace =True),\n            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1),\n            nn.ReLU(inplace =True)\n        )\n    def forward(self, x):\n        return self.conv_op(x)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:44:03.525318Z","iopub.execute_input":"2025-06-02T18:44:03.525700Z","iopub.status.idle":"2025-06-02T18:44:03.532294Z","shell.execute_reply.started":"2025-06-02T18:44:03.525677Z","shell.execute_reply":"2025-06-02T18:44:03.531257Z"}},"outputs":[],"execution_count":17},{"id":"c340b793","cell_type":"code","source":"## this downsample need to take care of as two conv and one max pooling\n\nclass DownSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = DoubleConv(in_channels, out_channels)\n        self.pool =nn.MaxPool2d(kernel_size =2, stride =2)\n    def forward(self, x):\n        down = self.conv(x) ## convolve, this need be saved for upsampling\n        p = self.pool(down) ## the pooling stuff\n        return down, p","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:44:05.937431Z","iopub.execute_input":"2025-06-02T18:44:05.937747Z","iopub.status.idle":"2025-06-02T18:44:05.945266Z","shell.execute_reply.started":"2025-06-02T18:44:05.937727Z","shell.execute_reply":"2025-06-02T18:44:05.943718Z"}},"outputs":[],"execution_count":18},{"id":"c21bd7d8-6bb3-43c8-af52-6898547f72b8","cell_type":"code","source":"class UpSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size =2, stride =2)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        x = torch.cat([x1,x2],1)\n        return self.conv(x)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:44:07.849103Z","iopub.execute_input":"2025-06-02T18:44:07.849477Z","iopub.status.idle":"2025-06-02T18:44:07.857974Z","shell.execute_reply.started":"2025-06-02T18:44:07.849447Z","shell.execute_reply":"2025-06-02T18:44:07.857225Z"}},"outputs":[],"execution_count":19},{"id":"c59ce611","cell_type":"code","source":"### Unet\n\nclass Unet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        self.down_conv1= DownDownSample(in_channels, 64) ## output is 64\n        self.down_conv2= DownDownSample(64, 128)\n        self.down_conv3= DownDownSample(128,256)\n        self.down_conv4= DownDownSample(256,512) \n\n        self.bottle_neck = DoubleConv(512, 1024)\n        \n        self.up_conv1= DownDownSample(1024, 512) ## output is 64\n        self.up_conv2= DownDownSample(512, 256)\n        self.up_conv3= DownDownSample(256,128)\n        self.up_conv4= DownDownSample(128,64)\n\n        self.out =nn.Conv2d(in_channels = 64, out_channels= num_classes, kernel_size =1)\n\n    def forward(self,x):\n        down_1, p1 = self.down_conv1(x)\n        down_2, p2 = self.down_conv2(p1)\n        down_3, p3 = self.down_conv3(p2)\n        down_4, p4 = self.down_conv4(p3)\n\n        b = self.bottle_neck(p4)\n\n        up1= self.up_conv1(b,down_4)\n        up2= self.up_conv2(up1,down_3)\n        up3= self.up_conv3(up2,down_2)\n        up4= self.up_conv4(up3,down_1)\n\n        out =self.out(up_4)\n        return out\n        \n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T18:58:26.981383Z","iopub.execute_input":"2025-06-02T18:58:26.981767Z","iopub.status.idle":"2025-06-02T18:58:26.990601Z","shell.execute_reply.started":"2025-06-02T18:58:26.981744Z","shell.execute_reply":"2025-06-02T18:58:26.989526Z"}},"outputs":[],"execution_count":21},{"id":"6a833220-5e40-458c-ab36-c3d0dc05006e","cell_type":"code","source":"## \n\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth = 1e-16):\n        super(DiceLoss, self).__init__()\n        self.smooth =smooth\n    def forward(self,inputs, targets):\n        inputs = inputs.view(-1)\n        targets =targets.view(-1)\n\n        intersection(inputs * targets).sum()\n        dice_score = (2 * intersection + self.smooth)/(inputs.sum() + targets.sum() + self.smooth)\n\n        return 1 - dice_score\n\n\n\nclass BCEWithDiceLoss(nn.Module): \n    def __init__(self, smooth =1e-6):\n        super(BCEWithDiceLoss, self).__init__()\n        self.bce =nn.BCEWithDiceLoss()\n        self.dice = DiceLoss()\n\n    def forward(self, inputs, targets):\n        bce_loss = self.bce(inputs, targets)\n        dice_loss =self.dice(inputs, targets)\n        return 0.5 * bce_loss + dice_loss\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T19:01:44.591666Z","iopub.execute_input":"2025-06-02T19:01:44.592711Z","iopub.status.idle":"2025-06-02T19:01:44.600690Z","shell.execute_reply.started":"2025-06-02T19:01:44.592678Z","shell.execute_reply":"2025-06-02T19:01:44.599253Z"}},"outputs":[],"execution_count":22},{"id":"a4cc5d17-4bd8-4735-8438-dcb01ed37b1f","cell_type":"code","source":"## Training Loss\n\ndef train(model, dataloader, epochs =2, lr =0.001, save_path  =\"unet_model\", load_path = None):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    if load_path and os.path.exists(load_path):\n        print(f\"Loading model weights  form{load_path}\")\n        model.load_state_dict(torch.load(load_path, map_location =device))\n    else : \n        print(f\"no checkpoint found, training from scratch..\")\n\n    print(device)\n    model.to(device)\n\n    criterion = BCEWithDiceLoss()\n\n    optimizer = SGD(model.parameters(), lr =lr)\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        \n        for images, masks, in dataloader:\n            images, masks = images.to(device), masks.to(device)\n            optimizer.zero_grad()\n\n            out = model(images)\n             loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"71b38b8c-dc9c-46ee-99e1-e3008403c097","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}