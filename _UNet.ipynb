{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4b7d3acc","cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\n\nfrom PIL import Image\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import Adam, AdamW, SGD","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:40.585247Z","iopub.execute_input":"2025-06-02T20:18:40.585896Z","iopub.status.idle":"2025-06-02T20:18:47.797238Z","shell.execute_reply.started":"2025-06-02T20:18:40.585869Z","shell.execute_reply":"2025-06-02T20:18:47.796661Z"}},"outputs":[],"execution_count":1},{"id":"daa5cf52","cell_type":"code","source":"!git clone https://github.com/VikramShenoy97/Human-Segmentation-Dataset.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:47.798519Z","iopub.execute_input":"2025-06-02T20:18:47.799111Z","iopub.status.idle":"2025-06-02T20:18:48.981284Z","shell.execute_reply.started":"2025-06-02T20:18:47.799091Z","shell.execute_reply":"2025-06-02T20:18:48.980382Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Human-Segmentation-Dataset'...\nremote: Enumerating objects: 596, done.\u001b[K\nremote: Total 596 (delta 0), reused 0 (delta 0), pack-reused 596 (from 1)\u001b[K\nReceiving objects: 100% (596/596), 13.60 MiB | 49.74 MiB/s, done.\nResolving deltas: 100% (7/7), done.\n","output_type":"stream"}],"execution_count":2},{"id":"570da81a","cell_type":"code","source":"class SegmentationDataset(Dataset):\n  def __init__(self, image_dir, mask_dir):\n    self.image_dir = image_dir\n    self.mask_dir = mask_dir\n    self.transform = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor()])\n\n    valid_extension = {\".jpg\", \".jpeg\", \".png\"}\n    self.images = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in valid_extension]\n\n  def __len__(self):\n    return len(self.images)\n\n  def __getitem__(self, idx):\n    img_path = os.path.join(self.image_dir, self.images[idx])\n    name, ext = os.path.splitext(self.images[idx])\n    mask_path = os.path.join(self.mask_dir, f\"{name}.png\")\n\n    image = Image.open(img_path).convert(\"RGB\")\n    mask = Image.open(mask_path).convert(\"L\")\n\n    image = self.transform(image)\n    mask = self.transform(mask)\n\n    mask = (mask > 0.5).float()\n\n    return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:48.982419Z","iopub.execute_input":"2025-06-02T20:18:48.982756Z","iopub.status.idle":"2025-06-02T20:18:48.989731Z","shell.execute_reply.started":"2025-06-02T20:18:48.982723Z","shell.execute_reply":"2025-06-02T20:18:48.988978Z"}},"outputs":[],"execution_count":3},{"id":"fee9f3b7","cell_type":"code","source":"## Data loader \n\ndef get_dataloader(image_dir, mask_dir, batch_size =2, shuffle =True):\n    dataset = SegmentationDataset(image_dir, mask_dir)\n    return DataLoader(dataset, batch_size = batch_size, shuffle =shuffle)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:48.991420Z","iopub.execute_input":"2025-06-02T20:18:48.991788Z","iopub.status.idle":"2025-06-02T20:18:49.004810Z","shell.execute_reply.started":"2025-06-02T20:18:48.991764Z","shell.execute_reply":"2025-06-02T20:18:49.004200Z"}},"outputs":[],"execution_count":4},{"id":"11cccdb3","cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv_op = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding =1),\n            nn.ReLU(inplace =True),\n            nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding =1),\n            nn.ReLU(inplace =True)\n        )\n    def forward(self, x):\n        return self.conv_op(x)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.005429Z","iopub.execute_input":"2025-06-02T20:18:49.005629Z","iopub.status.idle":"2025-06-02T20:18:49.019868Z","shell.execute_reply.started":"2025-06-02T20:18:49.005614Z","shell.execute_reply":"2025-06-02T20:18:49.019157Z"}},"outputs":[],"execution_count":5},{"id":"c340b793","cell_type":"code","source":"## this downsample need to take care of as two conv and one max pooling\n\nclass DownSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = DoubleConv(in_channels, out_channels)\n        self.pool =nn.MaxPool2d(kernel_size =2, stride =2)\n    def forward(self, x):\n        down = self.conv(x) ## convolve, this need be saved for upsampling\n        p = self.pool(down) ## the pooling stuff\n        return down, p","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.020485Z","iopub.execute_input":"2025-06-02T20:18:49.020738Z","iopub.status.idle":"2025-06-02T20:18:49.035246Z","shell.execute_reply.started":"2025-06-02T20:18:49.020717Z","shell.execute_reply":"2025-06-02T20:18:49.034618Z"}},"outputs":[],"execution_count":6},{"id":"c21bd7d8-6bb3-43c8-af52-6898547f72b8","cell_type":"code","source":"class UpSample(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        self.conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, x1, x2):\n       x1 = self.up(x1)\n       x = torch.cat([x1, x2], 1)\n       return self.conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.035907Z","iopub.execute_input":"2025-06-02T20:18:49.036131Z","iopub.status.idle":"2025-06-02T20:18:49.055069Z","shell.execute_reply.started":"2025-06-02T20:18:49.036111Z","shell.execute_reply":"2025-06-02T20:18:49.054401Z"}},"outputs":[],"execution_count":7},{"id":"c59ce611","cell_type":"code","source":"### Unet\n\nclass Unet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.down_conv1= DownSample(in_channels, 64) ## output is 64\n        self.down_conv2= DownSample(64, 128)\n        self.down_conv3= DownSample(128,256)\n        self.down_conv4= DownSample(256,512) \n\n        self.bottle_neck = DoubleConv(512, 1024)\n        \n        self.up_conv1= UpSample(1024, 512) \n        self.up_conv2= UpSample(512, 256)\n        self.up_conv3= UpSample(256,128)\n        self.up_conv4= UpSample(128,64)\n\n        self.out =nn.Conv2d(in_channels = 64, out_channels= num_classes, kernel_size =1)\n\n    def forward(self,x):\n        down_1, p1 = self.down_conv1(x)\n        down_2, p2 = self.down_conv2(p1)\n        down_3, p3 = self.down_conv3(p2)\n        down_4, p4 = self.down_conv4(p3)\n\n        b = self.bottle_neck(p4)\n\n        up1= self.up_conv1(b,down_4)\n        up2= self.up_conv2(up1,down_3)\n        up3= self.up_conv3(up2,down_2)\n        up4= self.up_conv4(up3,down_1)\n\n        out =self.out(up4)\n        return out\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.055787Z","iopub.execute_input":"2025-06-02T20:18:49.056071Z","iopub.status.idle":"2025-06-02T20:18:49.069826Z","shell.execute_reply.started":"2025-06-02T20:18:49.056044Z","shell.execute_reply":"2025-06-02T20:18:49.069291Z"}},"outputs":[],"execution_count":8},{"id":"6a833220-5e40-458c-ab36-c3d0dc05006e","cell_type":"code","source":"## \n\nclass DiceLoss(nn.Module):\n    def __init__(self, smooth = 1e-16):\n        super(DiceLoss, self).__init__()\n        self.smooth =smooth\n    def forward(self,inputs, targets):\n        inputs = inputs.view(-1)\n        targets =targets.view(-1)\n\n        intersection =(inputs * targets).sum()\n        dice_score = (2 * intersection + self.smooth)/(inputs.sum() + targets.sum() + self.smooth)\n\n        return 1 - dice_score\n\nclass BCEWithDiceLoss(nn.Module): \n    def __init__(self, smooth =1e-6):\n        super(BCEWithDiceLoss, self).__init__()\n        self.bce =nn.BCEWithLogitsLoss()\n        self.dice = DiceLoss()\n\n    def forward(self, inputs, targets):\n        bce_loss = self.bce(inputs, targets)\n        dice_loss =self.dice(inputs, targets)\n        return 0.5 * bce_loss + dice_loss\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.070461Z","iopub.execute_input":"2025-06-02T20:18:49.070673Z","iopub.status.idle":"2025-06-02T20:18:49.086151Z","shell.execute_reply.started":"2025-06-02T20:18:49.070653Z","shell.execute_reply":"2025-06-02T20:18:49.085481Z"}},"outputs":[],"execution_count":9},{"id":"a4cc5d17-4bd8-4735-8438-dcb01ed37b1f","cell_type":"code","source":"## Training loop  Loss\n\ndef train(model, dataloader, epochs =2, lr =0.001, save_path  =\"unet_model\", load_path = None):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    if load_path and os.path.exists(load_path):\n        print(f\"Loading model weights  from{load_path}\")\n        model.load_state_dict(torch.load(load_path, map_location=device))\n        \n    else : \n        print(f\"no checkpoint found, training from scratch..\")\n\n    print(device)\n    model.to(device)\n\n    criterion = BCEWithDiceLoss()\n\n    optimizer = SGD(model.parameters(), lr =lr)\n\n    for epoch in range(epochs):\n        model.train()\n        epoch_loss = 0\n        \n        for images, masks, in dataloader:\n            images, masks = images.to(device), masks.to(device)\n            optimizer.zero_grad()\n\n            output = model(images)\n            \n            loss =criterion(output, masks)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss +=loss.item()\n        \n        avg_loss =epoch_loss/ len(dataloader)\n\n        print(f\"epoch [{epoch+1}/{epochs}], Loss : {avg_loss: .4f}, LR: {lr}\")\n\n        if epoch %10==0 and epoch>0:\n            torch.save(model.state_dict(), f\"{save_path}.pth\")\n\n    torch.save(model.state_dict(), f\"{save_path}_final.pth\")\n    print(f\"Model_ saved to {save_path}\")\n\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.087929Z","iopub.execute_input":"2025-06-02T20:18:49.088127Z","iopub.status.idle":"2025-06-02T20:18:49.105094Z","shell.execute_reply.started":"2025-06-02T20:18:49.088114Z","shell.execute_reply":"2025-06-02T20:18:49.104557Z"}},"outputs":[],"execution_count":10},{"id":"71b38b8c-dc9c-46ee-99e1-e3008403c097","cell_type":"code","source":"dataloader = get_dataloader(\"/kaggle/working/Human-Segmentation-Dataset/Training_Images\", \"/kaggle/working/Human-Segmentation-Dataset/Ground_Truth\", batch_size =8, shuffle=True)\n\nmodel = Unet(in_channels=3, num_classes=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:18:49.105780Z","iopub.execute_input":"2025-06-02T20:18:49.105995Z","iopub.status.idle":"2025-06-02T20:18:49.390687Z","shell.execute_reply.started":"2025-06-02T20:18:49.105972Z","shell.execute_reply":"2025-06-02T20:18:49.389860Z"}},"outputs":[],"execution_count":11},{"id":"834cb76f","cell_type":"code","source":"train(model, dataloader, epochs =10, lr =0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:25:20.667210Z","iopub.execute_input":"2025-06-02T20:25:20.667868Z","iopub.status.idle":"2025-06-02T20:37:14.732020Z","shell.execute_reply.started":"2025-06-02T20:25:20.667839Z","shell.execute_reply":"2025-06-02T20:37:14.731256Z"}},"outputs":[{"name":"stdout","text":"no checkpoint found, training from scratch..\ncuda\nepoch [1/10], Loss :  1.1445, LR: 0.001\nepoch [2/10], Loss :  1.1295, LR: 0.001\nepoch [3/10], Loss :  1.1190, LR: 0.001\nepoch [4/10], Loss :  1.1084, LR: 0.001\nepoch [5/10], Loss :  1.1002, LR: 0.001\nepoch [6/10], Loss :  1.0978, LR: 0.001\nepoch [7/10], Loss :  1.0908, LR: 0.001\nepoch [8/10], Loss :  1.0856, LR: 0.001\nepoch [9/10], Loss :  1.0818, LR: 0.001\nepoch [10/10], Loss :  1.0765, LR: 0.001\nModel_ saved to unet_model\n","output_type":"stream"}],"execution_count":18},{"id":"4b6e408e","cell_type":"markdown","source":"### Inference on trained model","metadata":{}},{"id":"2bf65557","cell_type":"code","source":"import numpy as np\n\n# Load model and predict with stats\ndef predict(model_path, input_image_path):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    # Load model\n    model = Unet(in_channels=3, num_classes=1)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    # Track start time\n    total_start_time = time.time()\n\n    # Image preprocessing\n    preprocess_start_time = time.time()\n    image = Image.open(input_image_path).convert(\"RGB\")\n    transform = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n    ])\n    image_tensor = transform(image).unsqueeze(0).to(device)\n    preprocess_end_time = time.time()\n\n    # Model inference\n    inference_start_time = time.time()\n    with torch.no_grad():\n        output = model(image_tensor)\n        output = torch.sigmoid(output)\n    inference_end_time = time.time()\n\n    # Postprocessing\n    postprocess_start_time = time.time()\n    mask = output.squeeze(0).squeeze(0).cpu().numpy()\n    mask = (mask > 0.4).astype(np.uint8) * 255\n    mask_image = Image.fromarray(mask)\n\n    combined = Image.new(\"RGB\", (512 * 2, 512))\n    combined.paste(image.resize((512, 512)), (0, 0))\n    combined.paste(mask_image.convert(\"RGB\"), (512, 0))\n    combined.save(\"output.jpg\")\n    postprocess_end_time = time.time()\n\n    # Calculate timing stats\n    total_end_time = time.time()\n\n    preprocess_time = preprocess_end_time - preprocess_start_time\n    inference_time = inference_end_time - inference_start_time\n    postprocess_time = postprocess_end_time - postprocess_start_time\n    total_time = total_end_time - total_start_time\n\n    # Print stats\n    print(\"\\nPrediction completed! Stats:\")\n    print(f\"  Image Preprocessing Time: {preprocess_time:.4f} seconds\")\n    print(f\"  Model Inference Time: {inference_time:.4f} seconds\")\n    print(f\"  Postprocessing Time: {postprocess_time:.4f} seconds\")\n    print(f\"  Total Prediction Time: {total_time:.4f} seconds\")\n    print(\"Prediction saved as output.jpg\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:24:28.004720Z","iopub.execute_input":"2025-06-02T20:24:28.005545Z","iopub.status.idle":"2025-06-02T20:24:28.017254Z","shell.execute_reply.started":"2025-06-02T20:24:28.005497Z","shell.execute_reply":"2025-06-02T20:24:28.016389Z"}},"outputs":[],"execution_count":16},{"id":"afe10a45","cell_type":"code","source":"predict(model_path=\"/kaggle/working/unet_model_final.pth\", input_image_path=\"/kaggle/working/Human-Segmentation-Dataset/Training_Images/5.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:24:31.612588Z","iopub.execute_input":"2025-06-02T20:24:31.613187Z","iopub.status.idle":"2025-06-02T20:24:32.137039Z","shell.execute_reply.started":"2025-06-02T20:24:31.613165Z","shell.execute_reply":"2025-06-02T20:24:32.136440Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\nPrediction completed! Stats:\n  Image Preprocessing Time: 0.0059 seconds\n  Model Inference Time: 0.0228 seconds\n  Postprocessing Time: 0.1034 seconds\n  Total Prediction Time: 0.1321 seconds\nPrediction saved as output.jpg\n","output_type":"stream"}],"execution_count":17},{"id":"73fc774c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"213f6937","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}